{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "This script processes AP College Poll Top 25 voting for every week in the seasons from 2014 to 2024. It iteratively gathers\n",
    "poll data for all the weeks in a specified season and combines the data gathered from all seasons into a single merged CSV file.\n",
    "\n",
    "Input: URLs corresponding to AP College Poll ballot data for each week from 2014 to 2024.\n",
    "\n",
    "Output: \n",
    "1. One merged CSV file containing data from all weeks from 2014 to 2024.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def author_ballot_dictionary(Weeks, url, year, short_szn=True):\n",
    "    Dictionaries = []\n",
    "    final_week_offset = 0\n",
    "\n",
    "    #Iterate through weeks list and retrieves ballot data corresponding with the week \n",
    "    # at index i and the year that was passed as a function parameter\n",
    "    for i in range(len(Weeks)):\n",
    "        new_url = url + Weeks[i]\n",
    "        response = requests.get(new_url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        else:\n",
    "            print(\"bad\")\n",
    "            continue\n",
    "\n",
    "        #Accounts for the fact that short seasons do not have a 'week-16' and that 'final-rankings' \n",
    "        # should correspond with week 16 in the output csv file 'college_polls_original.csv'\n",
    "        if short_szn and i == len(Weeks) - 2:\n",
    "            final_week_offset = -1\n",
    "            continue\n",
    "\n",
    "        parent_element = soup.find('div', id='gridBallots')\n",
    "        Dict = {}\n",
    "        if parent_element:\n",
    "            Rows = parent_element.find_all('div', class_='gridRow')\n",
    "            for row in Rows:\n",
    "                author_name = (row.find('div', class_='gridPollster').find('a'))['href']\n",
    "                correct_author_name = author_name.split(\"/\")[3]\n",
    "                Team_rows = row.find_all('div', class_= 'gridTeam')\n",
    "\n",
    "                #Skips data retrieval of a pollster's vote in the situation where the pollster does not submit their votes \n",
    "                if Team_rows[0].get('class')[1][3:] == 'blank':\n",
    "                    continue\n",
    "\n",
    "                team_names = [correct_author_name, year, i + 1 + final_week_offset]\n",
    "                for item in Team_rows:\n",
    "                    #Extracts team name from item which is a string of the form: gi_{team_name}, by dropping the first 3 characters\n",
    "                    correct_team_name = item.get('class')[1][3:]\n",
    "                    team_names.append(correct_team_name)\n",
    "\n",
    "                Dict[correct_author_name] = team_names\n",
    "\n",
    "        Dictionaries.append(Dict)\n",
    "\n",
    "    return Dictionaries\n",
    "\n",
    "def csv_data_appender_by_year(year): \n",
    "    Weeks = ['pre-season', 'week-2', 'week-3', 'week-4', 'week-5', 'week-6', 'week-7', 'week-8', 'week-9', 'week-10', 'week-11', 'week-12', 'week-13', 'week-14', 'week-15', 'week-16', 'final-rankings']\n",
    "    url = \"https://collegepolltracker.com/football/grid/\" + year + \"/\"\n",
    "    long_szns = [\"2014\", \"2019\", \"2020\"]\n",
    "    \n",
    "    #Ensures no extraneous empty files made for seasons that have 16 weeks instead of 17 weeks\n",
    "    if year in long_szns:\n",
    "        Dictionaries = author_ballot_dictionary(Weeks, url, year, short_szn=False)\n",
    "    else:\n",
    "        Dictionaries = author_ballot_dictionary(Weeks, url, year)\n",
    "\n",
    "    #Iterates through dictionary containing individual votes for every week within the season and appends to the output\n",
    "    #  csv file 'college_polls_original.csv'\n",
    "    for dicto in Dictionaries:\n",
    "        df = pd.DataFrame.from_dict(dicto, orient='index', columns=['Pollster', 'Season', 'Week', '1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th', '11th', '12th', '13th', '14th', '15th', '16th', '17th', '18th', '19th', '20th', '21st', '22nd', '23rd', '24th', '25th'])\n",
    "        df.to_csv('college_polls_original.csv', mode='a', index=False, header=True)\n",
    "\n",
    "\n",
    "def csv_creation():\n",
    "    years = [\"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]\n",
    "    \n",
    "    #Clears the output csv file 'college_polls_original.csv' because the file write mode is set to append, ensuring that\n",
    "    #  no undesired content is in the file\n",
    "    f = open(\"college_polls_original.csv\", \"w\")\n",
    "    f.truncate()\n",
    "    f.close()\n",
    "\n",
    "    for year in years:\n",
    "        csv_data_appender_by_year(year)\n",
    "\n",
    "csv_creation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
