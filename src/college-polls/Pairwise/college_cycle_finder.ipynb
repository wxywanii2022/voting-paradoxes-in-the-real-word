{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "\n",
    "def preprocess_pairwise_data(pairwise_df):\n",
    "    \"\"\"\n",
    "    Preprocess the pairwise DataFrame to create a dictionary\n",
    "    for faster lookups.\n",
    "    \"\"\"\n",
    "    pairwise_dict = {}\n",
    "\n",
    "    for _, row in pairwise_df.iterrows():\n",
    "        team_a = row['TeamA']\n",
    "        team_b = row['TeamB']\n",
    "        a_b = (row['A>B'], row['B>A'])\n",
    "        pairwise_dict[(team_a, team_b)] = a_b\n",
    "        pairwise_dict[(team_b, team_a)] = (a_b[1], a_b[0])  # Reverse the order for (B, A)\n",
    "\n",
    "    return pairwise_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_team_rankings(ranking_file):\n",
    "    \"\"\"\n",
    "    Read the player rankings from a CSV file.\n",
    "    Returns a dictionary mapping teams to their rank and points.\n",
    "    \"\"\"\n",
    "    ranking_df = pd.read_csv(ranking_file)\n",
    "    ranking_df['Rank'] = ranking_df.index + 1  # Rank is based on the row number (1-indexed)\n",
    "    ranking_dict = {row['Teams']: {'Rank': row['Rank'], 'Points': row['Borda Points']}\n",
    "                    for _, row in ranking_df.iterrows()}\n",
    "    return ranking_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_finder_one_iteration(season, week):\n",
    "    # Read the nominees name list\n",
    "    data_path = f'C:\\\\Research\\\\VotingParadoxes\\\\data\\\\college-polls\\\\processed_data\\\\auxiliary_files\\\\voted_teams_by_season_and_week\\\\season_{season}\\\\{season}_week{week}_voted_teams.csv'\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "    except:\n",
    "        print(f'No valid data for {season} and {week}')\n",
    "        return\n",
    "    \n",
    "    # Extract the player names from the 'Player' column\n",
    "    name_list = df['Voted Teams'].tolist()\n",
    "\n",
    "    # Generate all possible 3-name combinations, sorted\n",
    "    combinations = [sorted(combo) for combo in itertools.combinations(name_list, 3)]\n",
    "\n",
    "    # Read the pairwise data CSV file (PlayerA, PlayerB, A>B, B>A)\n",
    "    pairwise_path = f'C:\\\\Research\\\\VotingParadoxes\\\\src\\\\college-polls\\\\Pairwise\\\\results\\\\season_{season}\\\\{season}_week{week}_condorcet.csv'\n",
    "    pairwise_df = pd.read_csv(pairwise_path)\n",
    "    \n",
    "    # Preprocess the pairwise data into a dictionary for faster lookups\n",
    "    pairwise_dict = preprocess_pairwise_data(pairwise_df)\n",
    "\n",
    "    # find team-rankings\n",
    "    rank_file = f\"./src/college-polls/Borda/results/borda_top25/season_{season}/{season}_week{week}_top25.csv\"\n",
    "    team_rankings = get_team_rankings(rank_file)\n",
    "    \n",
    "    # Iterate through each 3-player combination\n",
    "    valid_combinations = []\n",
    "    for combo in combinations:\n",
    "        a, b, c = combo\n",
    "\n",
    "        # Look up the results for each pair from the preprocessed dictionary\n",
    "        try:\n",
    "            a_b_result = pairwise_dict[(a, b)]\n",
    "            a_c_result = pairwise_dict[(a, c)]\n",
    "            b_c_result = pairwise_dict[(b, c)]\n",
    "        except KeyError:\n",
    "            continue  # Skip this combination if any pair data is missing\n",
    "        # Check the cycle conditions\n",
    "        if ((a_b_result[0] > a_b_result[1] and  # A > B\n",
    "            b_c_result[0] > b_c_result[1] and  # B > C\n",
    "            a_c_result[1] > a_c_result[0]) or  # C > A\n",
    "            (a_b_result[1] > a_b_result[0] and  # A < B\n",
    "            b_c_result[1] > b_c_result[0] and  # B < C\n",
    "            a_c_result[0] > a_c_result[1])):    # C < A\n",
    "            \n",
    "            a_rank = team_rankings.get(a, {'Rank': 'N/A', 'Points': 'N/A'})\n",
    "            b_rank = team_rankings.get(b, {'Rank': 'N/A', 'Points': 'N/A'})\n",
    "            c_rank = team_rankings.get(c, {'Rank': 'N/A', 'Points': 'N/A'})\n",
    "\n",
    "            valid_combinations.append({\n",
    "                'Season': season,\n",
    "                'Week': week,\n",
    "                'Combo': f'{a}, {b}, {c}',\n",
    "                'Ranks': f'{a_rank[\"Rank\"]}, {b_rank[\"Rank\"]}, {c_rank[\"Rank\"]}',\n",
    "                'ab': f'({a}, {b})',\n",
    "                'ab-a': f'{a_b_result[0]}',\n",
    "                'ab-b': f'{a_b_result[1]}',\n",
    "                'bc': f'({b}, {c})', \n",
    "                'bc-b': f'{b_c_result[0]}', \n",
    "                'bc-c': f'{b_c_result[1]}', \n",
    "                'ca': f'({c}, {a})', \n",
    "                'ca-c': f'{a_c_result[1]}', \n",
    "                'ca-a': f'{a_c_result[0]}'\n",
    "            })\n",
    "\n",
    "    # Convert the valid combinations to a DataFrame\n",
    "    valid_combos_df = pd.DataFrame(valid_combinations)\n",
    "    return valid_combos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_college_cycles():\n",
    "    seasons = range(2014, 2025)  \n",
    "    weeks = range(1, 18)\n",
    "\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    for season in seasons:\n",
    "        for week in weeks:\n",
    "            print(f\"Processing year {season}, week {week}...\")\n",
    "            result_df = cycle_finder_one_iteration(season, week)\n",
    "            results_df = pd.concat([results_df, result_df], ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file with a clean format\n",
    "    results_df.to_csv(f'C:\\\\Research\\\\VotingParadoxes\\\\src\\\\college-polls\\\\Pairwise\\\\all-cycles.csv', index=False)\n",
    "    print(\"All data has been processed and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'florida-state-seminoles': {'Rank': 1, 'Points': 1496},\n",
       " 'alabama-crimson-tide': {'Rank': 2, 'Points': 1361},\n",
       " 'oregon-ducks': {'Rank': 3, 'Points': 1334},\n",
       " 'oklahoma-sooners': {'Rank': 4, 'Points': 1324},\n",
       " 'ohio-state-buckeyes': {'Rank': 5, 'Points': 1207},\n",
       " 'auburn-tigers': {'Rank': 6, 'Points': 1198},\n",
       " 'ucla-bruins': {'Rank': 7, 'Points': 1106},\n",
       " 'michigan-state-spartans': {'Rank': 8, 'Points': 1080},\n",
       " 'south-carolina-gamecocks': {'Rank': 9, 'Points': 1015},\n",
       " 'baylor-bears': {'Rank': 10, 'Points': 966},\n",
       " 'stanford-cardinal': {'Rank': 11, 'Points': 885},\n",
       " 'georgia-bulldogs': {'Rank': 12, 'Points': 843},\n",
       " 'lsu-tigers': {'Rank': 13, 'Points': 776},\n",
       " 'wisconsin-badgers': {'Rank': 14, 'Points': 637},\n",
       " 'usc-trojans': {'Rank': 15, 'Points': 626},\n",
       " 'clemson-tigers': {'Rank': 16, 'Points': 536},\n",
       " 'notre-dame-fighting-irish': {'Rank': 17, 'Points': 445},\n",
       " 'ole-miss-rebels': {'Rank': 18, 'Points': 424},\n",
       " 'arizona-state-sun-devils': {'Rank': 19, 'Points': 357},\n",
       " 'kansas-state-wildcats': {'Rank': 20, 'Points': 242},\n",
       " 'texas-am-aggies': {'Rank': 21, 'Points': 238},\n",
       " 'nebraska-cornhuskers': {'Rank': 22, 'Points': 226},\n",
       " 'north-carolina-tar-heels': {'Rank': 23, 'Points': 194},\n",
       " 'missouri-tigers': {'Rank': 24, 'Points': 134},\n",
       " 'washington-huskies': {'Rank': 25, 'Points': 130},\n",
       " 'ucf-knights': {'Rank': 26, 'Points': 94},\n",
       " 'florida-gators': {'Rank': 27, 'Points': 87},\n",
       " 'texas-longhorns': {'Rank': 28, 'Points': 86},\n",
       " 'duke-blue-devils': {'Rank': 29, 'Points': 71},\n",
       " 'iowa-hawkeyes': {'Rank': 30, 'Points': 68},\n",
       " 'louisville-cardinals': {'Rank': 31, 'Points': 48},\n",
       " 'marshall-thundering-herd': {'Rank': 32, 'Points': 41},\n",
       " 'oklahoma-state-cowboys': {'Rank': 33, 'Points': 37},\n",
       " 'virginia-tech-hokies': {'Rank': 34, 'Points': 26},\n",
       " 'tcu-horned-frogs': {'Rank': 35, 'Points': 23},\n",
       " 'mississippi-state-bulldogs': {'Rank': 36, 'Points': 22},\n",
       " 'michigan-wolverines': {'Rank': 37, 'Points': 19},\n",
       " 'texas-tech-red-raiders': {'Rank': 38, 'Points': 19},\n",
       " 'miami-fl-hurricanes': {'Rank': 39, 'Points': 16},\n",
       " 'cincinnati-bearcats': {'Rank': 40, 'Points': 15},\n",
       " 'oregon-state-beavers': {'Rank': 41, 'Points': 10},\n",
       " 'boise-state-broncos': {'Rank': 42, 'Points': 10},\n",
       " 'northwestern-wildcats': {'Rank': 43, 'Points': 8},\n",
       " 'byu-cougars': {'Rank': 44, 'Points': 8},\n",
       " 'penn-state-nittany-lions': {'Rank': 45, 'Points': 5},\n",
       " 'navy-midshipmen': {'Rank': 46, 'Points': 2},\n",
       " 'vanderbilt-commodores': {'Rank': 47, 'Points': 2},\n",
       " 'utah-state-aggies': {'Rank': 48, 'Points': 1},\n",
       " 'louisiana-lafayette-ragin-cajuns': {'Rank': 49, 'Points': 1},\n",
       " 'nevada-wolf-pack': {'Rank': 50, 'Points': 1}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_team_rankings(f\"./src/college-polls/Borda/results/borda_top25/season_2014/2014_week1_top25.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing year 2014, week 1...\n",
      "Processing year 2014, week 2...\n",
      "Processing year 2014, week 3...\n",
      "Processing year 2014, week 4...\n",
      "Processing year 2014, week 5...\n",
      "Processing year 2014, week 6...\n",
      "Processing year 2014, week 7...\n",
      "Processing year 2014, week 8...\n",
      "Processing year 2014, week 9...\n",
      "Processing year 2014, week 10...\n",
      "Processing year 2014, week 11...\n",
      "Processing year 2014, week 12...\n",
      "Processing year 2014, week 13...\n",
      "Processing year 2014, week 14...\n",
      "Processing year 2014, week 15...\n",
      "Processing year 2014, week 16...\n",
      "Processing year 2014, week 17...\n",
      "Processing year 2015, week 1...\n",
      "Processing year 2015, week 2...\n",
      "No valid data for 2015 and 2\n",
      "Processing year 2015, week 3...\n",
      "Processing year 2015, week 4...\n",
      "Processing year 2015, week 5...\n",
      "Processing year 2015, week 6...\n",
      "Processing year 2015, week 7...\n",
      "Processing year 2015, week 8...\n",
      "Processing year 2015, week 9...\n",
      "Processing year 2015, week 10...\n",
      "Processing year 2015, week 11...\n",
      "Processing year 2015, week 12...\n",
      "Processing year 2015, week 13...\n",
      "Processing year 2015, week 14...\n",
      "Processing year 2015, week 15...\n",
      "Processing year 2015, week 16...\n",
      "Processing year 2015, week 17...\n",
      "No valid data for 2015 and 17\n",
      "Processing year 2016, week 1...\n",
      "Processing year 2016, week 2...\n",
      "Processing year 2016, week 3...\n",
      "Processing year 2016, week 4...\n",
      "Processing year 2016, week 5...\n",
      "Processing year 2016, week 6...\n",
      "Processing year 2016, week 7...\n",
      "Processing year 2016, week 8...\n",
      "Processing year 2016, week 9...\n",
      "Processing year 2016, week 10...\n",
      "Processing year 2016, week 11...\n",
      "Processing year 2016, week 12...\n",
      "Processing year 2016, week 13...\n",
      "Processing year 2016, week 14...\n",
      "Processing year 2016, week 15...\n",
      "Processing year 2016, week 16...\n",
      "Processing year 2016, week 17...\n",
      "No valid data for 2016 and 17\n",
      "Processing year 2017, week 1...\n",
      "Processing year 2017, week 2...\n",
      "Processing year 2017, week 3...\n",
      "Processing year 2017, week 4...\n",
      "Processing year 2017, week 5...\n",
      "Processing year 2017, week 6...\n",
      "Processing year 2017, week 7...\n",
      "Processing year 2017, week 8...\n",
      "Processing year 2017, week 9...\n",
      "Processing year 2017, week 10...\n",
      "Processing year 2017, week 11...\n",
      "Processing year 2017, week 12...\n",
      "Processing year 2017, week 13...\n",
      "Processing year 2017, week 14...\n",
      "Processing year 2017, week 15...\n",
      "Processing year 2017, week 16...\n",
      "Processing year 2017, week 17...\n",
      "No valid data for 2017 and 17\n",
      "Processing year 2018, week 1...\n",
      "Processing year 2018, week 2...\n",
      "Processing year 2018, week 3...\n",
      "Processing year 2018, week 4...\n",
      "Processing year 2018, week 5...\n",
      "Processing year 2018, week 6...\n",
      "Processing year 2018, week 7...\n",
      "Processing year 2018, week 8...\n",
      "Processing year 2018, week 9...\n",
      "Processing year 2018, week 10...\n",
      "Processing year 2018, week 11...\n",
      "Processing year 2018, week 12...\n",
      "Processing year 2018, week 13...\n",
      "Processing year 2018, week 14...\n",
      "Processing year 2018, week 15...\n",
      "Processing year 2018, week 16...\n",
      "Processing year 2018, week 17...\n",
      "No valid data for 2018 and 17\n",
      "Processing year 2019, week 1...\n",
      "Processing year 2019, week 2...\n",
      "Processing year 2019, week 3...\n",
      "Processing year 2019, week 4...\n",
      "Processing year 2019, week 5...\n",
      "Processing year 2019, week 6...\n",
      "Processing year 2019, week 7...\n",
      "Processing year 2019, week 8...\n",
      "Processing year 2019, week 9...\n",
      "Processing year 2019, week 10...\n",
      "Processing year 2019, week 11...\n",
      "Processing year 2019, week 12...\n",
      "Processing year 2019, week 13...\n",
      "Processing year 2019, week 14...\n",
      "Processing year 2019, week 15...\n",
      "Processing year 2019, week 16...\n",
      "Processing year 2019, week 17...\n",
      "Processing year 2020, week 1...\n",
      "Processing year 2020, week 2...\n",
      "Processing year 2020, week 3...\n",
      "Processing year 2020, week 4...\n",
      "Processing year 2020, week 5...\n",
      "Processing year 2020, week 6...\n",
      "Processing year 2020, week 7...\n",
      "Processing year 2020, week 8...\n",
      "Processing year 2020, week 9...\n",
      "Processing year 2020, week 10...\n",
      "Processing year 2020, week 11...\n",
      "Processing year 2020, week 12...\n",
      "Processing year 2020, week 13...\n",
      "Processing year 2020, week 14...\n",
      "Processing year 2020, week 15...\n",
      "Processing year 2020, week 16...\n",
      "Processing year 2020, week 17...\n",
      "Processing year 2021, week 1...\n",
      "Processing year 2021, week 2...\n",
      "Processing year 2021, week 3...\n",
      "Processing year 2021, week 4...\n",
      "Processing year 2021, week 5...\n",
      "Processing year 2021, week 6...\n",
      "Processing year 2021, week 7...\n",
      "Processing year 2021, week 8...\n",
      "Processing year 2021, week 9...\n",
      "Processing year 2021, week 10...\n",
      "Processing year 2021, week 11...\n",
      "Processing year 2021, week 12...\n",
      "Processing year 2021, week 13...\n",
      "Processing year 2021, week 14...\n",
      "Processing year 2021, week 15...\n",
      "Processing year 2021, week 16...\n",
      "Processing year 2021, week 17...\n",
      "No valid data for 2021 and 17\n",
      "Processing year 2022, week 1...\n",
      "Processing year 2022, week 2...\n",
      "Processing year 2022, week 3...\n",
      "Processing year 2022, week 4...\n",
      "Processing year 2022, week 5...\n",
      "Processing year 2022, week 6...\n",
      "Processing year 2022, week 7...\n",
      "Processing year 2022, week 8...\n",
      "Processing year 2022, week 9...\n",
      "Processing year 2022, week 10...\n",
      "Processing year 2022, week 11...\n",
      "Processing year 2022, week 12...\n",
      "Processing year 2022, week 13...\n",
      "Processing year 2022, week 14...\n",
      "Processing year 2022, week 15...\n",
      "Processing year 2022, week 16...\n",
      "Processing year 2022, week 17...\n",
      "No valid data for 2022 and 17\n",
      "Processing year 2023, week 1...\n",
      "Processing year 2023, week 2...\n",
      "Processing year 2023, week 3...\n",
      "Processing year 2023, week 4...\n",
      "Processing year 2023, week 5...\n",
      "Processing year 2023, week 6...\n",
      "Processing year 2023, week 7...\n",
      "Processing year 2023, week 8...\n",
      "Processing year 2023, week 9...\n",
      "Processing year 2023, week 10...\n",
      "Processing year 2023, week 11...\n",
      "Processing year 2023, week 12...\n",
      "Processing year 2023, week 13...\n",
      "Processing year 2023, week 14...\n",
      "Processing year 2023, week 15...\n",
      "Processing year 2023, week 16...\n",
      "Processing year 2023, week 17...\n",
      "No valid data for 2023 and 17\n",
      "Processing year 2024, week 1...\n",
      "Processing year 2024, week 2...\n",
      "Processing year 2024, week 3...\n",
      "Processing year 2024, week 4...\n",
      "Processing year 2024, week 5...\n",
      "Processing year 2024, week 6...\n",
      "No valid data for 2024 and 6\n",
      "Processing year 2024, week 7...\n",
      "No valid data for 2024 and 7\n",
      "Processing year 2024, week 8...\n",
      "No valid data for 2024 and 8\n",
      "Processing year 2024, week 9...\n",
      "No valid data for 2024 and 9\n",
      "Processing year 2024, week 10...\n",
      "No valid data for 2024 and 10\n",
      "Processing year 2024, week 11...\n",
      "No valid data for 2024 and 11\n",
      "Processing year 2024, week 12...\n",
      "No valid data for 2024 and 12\n",
      "Processing year 2024, week 13...\n",
      "No valid data for 2024 and 13\n",
      "Processing year 2024, week 14...\n",
      "No valid data for 2024 and 14\n",
      "Processing year 2024, week 15...\n",
      "No valid data for 2024 and 15\n",
      "Processing year 2024, week 16...\n",
      "No valid data for 2024 and 16\n",
      "Processing year 2024, week 17...\n",
      "No valid data for 2024 and 17\n",
      "All data has been processed and saved\n"
     ]
    }
   ],
   "source": [
    "all_college_cycles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_finder_4(season, week):\n",
    "\n",
    "    data_path = f'C:\\\\Research\\\\VotingParadoxes\\\\data\\\\college-polls\\\\processed_data\\\\auxiliary_files\\\\voted_teams_by_season_and_week\\\\season_{season}\\\\{season}_week{week}_voted_teams.csv'\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "    except:\n",
    "        print(f'No valid data for {season} and {week}')\n",
    "        return\n",
    "\n",
    "    team_list = df['Voted Teams'].tolist()\n",
    "\n",
    "    combinations = [sorted(combo) for combo in itertools.combinations(team_list, 4)]\n",
    "\n",
    "    pairwise_path = f'C:\\\\Research\\\\VotingParadoxes\\\\src\\\\college-polls\\\\Pairwise\\\\results\\\\season_{season}\\\\{season}_week{week}_condorcet.csv'\n",
    "    pairwise_df = pd.read_csv(pairwise_path)\n",
    "    \n",
    "    pairwise_dict = preprocess_pairwise_data(pairwise_df)\n",
    "\n",
    "    rank_file = f\"./src/college-polls/Borda/results/borda_top25/season_{season}/{season}_week{week}_top25.csv\"\n",
    "    team_rankings = get_team_rankings(rank_file)\n",
    "    \n",
    "    # Iterate through each 4-player combination\n",
    "    valid_combinations = []\n",
    "    for combo in combinations:\n",
    "        a, b, c, d = combo\n",
    "        try:\n",
    "            a_b_result = pairwise_dict[(a, b)]\n",
    "            a_c_result = pairwise_dict[(a, c)]\n",
    "            a_d_result = pairwise_dict[(a, d)]\n",
    "            b_c_result = pairwise_dict[(b, c)]\n",
    "            b_d_result = pairwise_dict[(b, d)]\n",
    "            c_d_result = pairwise_dict[(c, d)]\n",
    "        except KeyError:\n",
    "            continue  # Skip this combination if any pair data is missing\n",
    "\n",
    "        # A>B, B>C, C>D, D>A OR A<B, B<C, C<D, D<A\n",
    "        if ((a_b_result[0] > a_b_result[1] and  \n",
    "            b_c_result[0] > b_c_result[1] and  \n",
    "            c_d_result[0] > c_d_result[1] and  \n",
    "            a_d_result[1] > a_d_result[0]) or \n",
    "            (a_b_result[1] > a_b_result[0] and  \n",
    "            b_c_result[1] > b_c_result[0] and  \n",
    "            c_d_result[1] > c_d_result[0] and  \n",
    "            a_d_result[0] > a_d_result[1])):   \n",
    "            \n",
    "            a_rank = team_rankings.get(a, {'Rank': 'N/A', 'Points': 'N/A'})\n",
    "            b_rank = team_rankings.get(b, {'Rank': 'N/A', 'Points': 'N/A'})\n",
    "            c_rank = team_rankings.get(c, {'Rank': 'N/A', 'Points': 'N/A'})\n",
    "            d_rank = team_rankings.get(d, {'Rank': 'N/A', 'Points': 'N/A'})\n",
    "\n",
    "            valid_combinations.append({\n",
    "                'Season': season,\n",
    "                'Week': week,\n",
    "                'Combo': f'{a}, {b}, {c}, {d}',\n",
    "                'Ranks': f'{a_rank[\"Rank\"]}, {b_rank[\"Rank\"]}, {c_rank[\"Rank\"]}, {d_rank[\"Rank\"]}',\n",
    "                'ab': f'({a} {b})',\n",
    "                'a>b': f'{a_b_result[0]}',\n",
    "                'b>a': f'{a_b_result[1]}',\n",
    "                'bc': f'({b} {c})', \n",
    "                'b>c': f'{b_c_result[0]}', \n",
    "                'c>b': f'{b_c_result[1]}',\n",
    "                'cd': f'({c} {d})',\n",
    "                'c>d': f'{c_d_result[0]}',\n",
    "                'd>c': f'{c_d_result[1]}',\n",
    "                'da': f'({d} {a})',\n",
    "                'd>a': f'{a_d_result[1]}',\n",
    "                'a>d': f'{a_d_result[0]}'\n",
    "            })\n",
    "\n",
    "    valid_combos_df = pd.DataFrame(valid_combinations)\n",
    "    return valid_combos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_through_4cycle():\n",
    "    seasons = range(2014, 2025)  \n",
    "    weeks = range(1, 18)\n",
    "\n",
    "    all_results_df = pd.DataFrame()\n",
    "\n",
    "    for season in seasons:\n",
    "        for week in weeks:\n",
    "            print(f\"Processing season {season}, week {week}...\")\n",
    "            result_df = cycle_finder_4(season, week)\n",
    "            all_results_df = pd.concat([all_results_df, result_df], ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file with a clean format\n",
    "    all_results_df.to_csv(\"./src/college-polls/Pairwise/4_cycle.csv\", index=False)\n",
    "    print(\"All data has been processed and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Research\\VotingParadoxes\n",
      "c:\\Research\\VotingParadoxes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('c:\\Research\\VotingParadoxes')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing season 2014, week 1...\n",
      "Processing season 2014, week 2...\n",
      "Processing season 2014, week 3...\n",
      "Processing season 2014, week 4...\n",
      "Processing season 2014, week 5...\n",
      "Processing season 2014, week 6...\n",
      "Processing season 2014, week 7...\n",
      "Processing season 2014, week 8...\n",
      "Processing season 2014, week 9...\n",
      "Processing season 2014, week 10...\n",
      "Processing season 2014, week 11...\n",
      "Processing season 2014, week 12...\n",
      "Processing season 2014, week 13...\n",
      "Processing season 2014, week 14...\n",
      "Processing season 2014, week 15...\n",
      "Processing season 2014, week 16...\n",
      "Processing season 2014, week 17...\n",
      "Processing season 2015, week 1...\n",
      "Processing season 2015, week 2...\n",
      "No valid data for 2015 and 2\n",
      "Processing season 2015, week 3...\n",
      "Processing season 2015, week 4...\n",
      "Processing season 2015, week 5...\n",
      "Processing season 2015, week 6...\n",
      "Processing season 2015, week 7...\n",
      "Processing season 2015, week 8...\n",
      "Processing season 2015, week 9...\n",
      "Processing season 2015, week 10...\n",
      "Processing season 2015, week 11...\n",
      "Processing season 2015, week 12...\n",
      "Processing season 2015, week 13...\n",
      "Processing season 2015, week 14...\n",
      "Processing season 2015, week 15...\n",
      "Processing season 2015, week 16...\n",
      "Processing season 2015, week 17...\n",
      "No valid data for 2015 and 17\n",
      "Processing season 2016, week 1...\n",
      "Processing season 2016, week 2...\n",
      "Processing season 2016, week 3...\n",
      "Processing season 2016, week 4...\n",
      "Processing season 2016, week 5...\n",
      "Processing season 2016, week 6...\n",
      "Processing season 2016, week 7...\n",
      "Processing season 2016, week 8...\n",
      "Processing season 2016, week 9...\n",
      "Processing season 2016, week 10...\n",
      "Processing season 2016, week 11...\n",
      "Processing season 2016, week 12...\n",
      "Processing season 2016, week 13...\n",
      "Processing season 2016, week 14...\n",
      "Processing season 2016, week 15...\n",
      "Processing season 2016, week 16...\n",
      "Processing season 2016, week 17...\n",
      "No valid data for 2016 and 17\n",
      "Processing season 2017, week 1...\n",
      "Processing season 2017, week 2...\n",
      "Processing season 2017, week 3...\n",
      "Processing season 2017, week 4...\n",
      "Processing season 2017, week 5...\n",
      "Processing season 2017, week 6...\n",
      "Processing season 2017, week 7...\n",
      "Processing season 2017, week 8...\n",
      "Processing season 2017, week 9...\n",
      "Processing season 2017, week 10...\n",
      "Processing season 2017, week 11...\n",
      "Processing season 2017, week 12...\n",
      "Processing season 2017, week 13...\n",
      "Processing season 2017, week 14...\n",
      "Processing season 2017, week 15...\n",
      "Processing season 2017, week 16...\n",
      "Processing season 2017, week 17...\n",
      "No valid data for 2017 and 17\n",
      "Processing season 2018, week 1...\n",
      "Processing season 2018, week 2...\n",
      "Processing season 2018, week 3...\n",
      "Processing season 2018, week 4...\n",
      "Processing season 2018, week 5...\n",
      "Processing season 2018, week 6...\n",
      "Processing season 2018, week 7...\n",
      "Processing season 2018, week 8...\n",
      "Processing season 2018, week 9...\n",
      "Processing season 2018, week 10...\n",
      "Processing season 2018, week 11...\n",
      "Processing season 2018, week 12...\n",
      "Processing season 2018, week 13...\n",
      "Processing season 2018, week 14...\n",
      "Processing season 2018, week 15...\n",
      "Processing season 2018, week 16...\n",
      "Processing season 2018, week 17...\n",
      "No valid data for 2018 and 17\n",
      "Processing season 2019, week 1...\n",
      "Processing season 2019, week 2...\n",
      "Processing season 2019, week 3...\n",
      "Processing season 2019, week 4...\n",
      "Processing season 2019, week 5...\n",
      "Processing season 2019, week 6...\n",
      "Processing season 2019, week 7...\n",
      "Processing season 2019, week 8...\n",
      "Processing season 2019, week 9...\n",
      "Processing season 2019, week 10...\n",
      "Processing season 2019, week 11...\n",
      "Processing season 2019, week 12...\n",
      "Processing season 2019, week 13...\n",
      "Processing season 2019, week 14...\n",
      "Processing season 2019, week 15...\n",
      "Processing season 2019, week 16...\n",
      "Processing season 2019, week 17...\n",
      "Processing season 2020, week 1...\n",
      "Processing season 2020, week 2...\n",
      "Processing season 2020, week 3...\n",
      "Processing season 2020, week 4...\n",
      "Processing season 2020, week 5...\n",
      "Processing season 2020, week 6...\n",
      "Processing season 2020, week 7...\n",
      "Processing season 2020, week 8...\n",
      "Processing season 2020, week 9...\n",
      "Processing season 2020, week 10...\n",
      "Processing season 2020, week 11...\n",
      "Processing season 2020, week 12...\n",
      "Processing season 2020, week 13...\n",
      "Processing season 2020, week 14...\n",
      "Processing season 2020, week 15...\n",
      "Processing season 2020, week 16...\n",
      "Processing season 2020, week 17...\n",
      "Processing season 2021, week 1...\n",
      "Processing season 2021, week 2...\n",
      "Processing season 2021, week 3...\n",
      "Processing season 2021, week 4...\n",
      "Processing season 2021, week 5...\n",
      "Processing season 2021, week 6...\n",
      "Processing season 2021, week 7...\n",
      "Processing season 2021, week 8...\n",
      "Processing season 2021, week 9...\n",
      "Processing season 2021, week 10...\n",
      "Processing season 2021, week 11...\n",
      "Processing season 2021, week 12...\n",
      "Processing season 2021, week 13...\n",
      "Processing season 2021, week 14...\n",
      "Processing season 2021, week 15...\n",
      "Processing season 2021, week 16...\n",
      "Processing season 2021, week 17...\n",
      "No valid data for 2021 and 17\n",
      "Processing season 2022, week 1...\n",
      "Processing season 2022, week 2...\n",
      "Processing season 2022, week 3...\n",
      "Processing season 2022, week 4...\n",
      "Processing season 2022, week 5...\n",
      "Processing season 2022, week 6...\n",
      "Processing season 2022, week 7...\n",
      "Processing season 2022, week 8...\n",
      "Processing season 2022, week 9...\n",
      "Processing season 2022, week 10...\n",
      "Processing season 2022, week 11...\n",
      "Processing season 2022, week 12...\n",
      "Processing season 2022, week 13...\n",
      "Processing season 2022, week 14...\n",
      "Processing season 2022, week 15...\n",
      "Processing season 2022, week 16...\n",
      "Processing season 2022, week 17...\n",
      "No valid data for 2022 and 17\n",
      "Processing season 2023, week 1...\n",
      "Processing season 2023, week 2...\n",
      "Processing season 2023, week 3...\n",
      "Processing season 2023, week 4...\n",
      "Processing season 2023, week 5...\n",
      "Processing season 2023, week 6...\n",
      "Processing season 2023, week 7...\n",
      "Processing season 2023, week 8...\n",
      "Processing season 2023, week 9...\n",
      "Processing season 2023, week 10...\n",
      "Processing season 2023, week 11...\n",
      "Processing season 2023, week 12...\n",
      "Processing season 2023, week 13...\n",
      "Processing season 2023, week 14...\n",
      "Processing season 2023, week 15...\n",
      "Processing season 2023, week 16...\n",
      "Processing season 2023, week 17...\n",
      "No valid data for 2023 and 17\n",
      "Processing season 2024, week 1...\n",
      "Processing season 2024, week 2...\n",
      "Processing season 2024, week 3...\n",
      "Processing season 2024, week 4...\n",
      "Processing season 2024, week 5...\n",
      "Processing season 2024, week 6...\n",
      "No valid data for 2024 and 6\n",
      "Processing season 2024, week 7...\n",
      "No valid data for 2024 and 7\n",
      "Processing season 2024, week 8...\n",
      "No valid data for 2024 and 8\n",
      "Processing season 2024, week 9...\n",
      "No valid data for 2024 and 9\n",
      "Processing season 2024, week 10...\n",
      "No valid data for 2024 and 10\n",
      "Processing season 2024, week 11...\n",
      "No valid data for 2024 and 11\n",
      "Processing season 2024, week 12...\n",
      "No valid data for 2024 and 12\n",
      "Processing season 2024, week 13...\n",
      "No valid data for 2024 and 13\n",
      "Processing season 2024, week 14...\n",
      "No valid data for 2024 and 14\n",
      "Processing season 2024, week 15...\n",
      "No valid data for 2024 and 15\n",
      "Processing season 2024, week 16...\n",
      "No valid data for 2024 and 16\n",
      "Processing season 2024, week 17...\n",
      "No valid data for 2024 and 17\n",
      "All data has been processed and saved\n"
     ]
    }
   ],
   "source": [
    "cycle_through_4cycle()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_finder_5(season, week):\n",
    "\n",
    "    data_path = f'C:\\\\Research\\\\VotingParadoxes\\\\data\\\\college-polls\\\\processed_data\\\\auxiliary_files\\\\voted_teams_by_season_and_week\\\\season_{season}\\\\{season}_week{week}_voted_teams.csv'\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "    except:\n",
    "        print(f'No valid data for {season} and {week}')\n",
    "        return\n",
    "\n",
    "    team_list = df['Voted Teams'].tolist()\n",
    "\n",
    "    combinations = [sorted(combo) for combo in itertools.combinations(team_list, 5)]\n",
    "\n",
    "    pairwise_path = f'C:\\\\Research\\\\VotingParadoxes\\\\src\\\\college-polls\\\\Pairwise\\\\results\\\\season_{season}\\\\{season}_week{week}_condorcet.csv'\n",
    "    pairwise_df = pd.read_csv(pairwise_path)\n",
    "    \n",
    "    pairwise_dict = preprocess_pairwise_data(pairwise_df)\n",
    "\n",
    "    rank_file = f\"./src/college-polls/Borda/results/borda_top25/season_{season}/{season}_week{week}_top25.csv\"\n",
    "    team_rankings = get_team_rankings(rank_file)\n",
    "    \n",
    "    # Iterate through each 4-player combination\n",
    "    valid_combinations = []\n",
    "    for combo in combinations:\n",
    "        a, b, c, d, e = combo\n",
    "        try:\n",
    "            a_b_result = pairwise_dict[(a, b)]\n",
    "            a_c_result = pairwise_dict[(a, c)]\n",
    "            a_d_result = pairwise_dict[(a, d)]\n",
    "            a_e_result = pairwise_dict[(a, e)]\n",
    "            b_c_result = pairwise_dict[(b, c)]\n",
    "            b_d_result = pairwise_dict[(b, d)]\n",
    "            b_e_result = pairwise_dict[(b, e)]\n",
    "            c_d_result = pairwise_dict[(c, d)]\n",
    "            c_e_result = pairwise_dict[(c, e)]\n",
    "            d_e_result = pairwise_dict[(d, e)]\n",
    "        except KeyError:\n",
    "            continue \n",
    "\n",
    "        # A>B, B>C, C>D, D>E, E>A OR A<B, B<C, C<D, D<E, E<A\n",
    "        if ((a_b_result[0] > a_b_result[1] and\n",
    "            b_c_result[0] > b_c_result[1] and\n",
    "            c_d_result[0] > c_d_result[1] and\n",
    "            d_e_result[0] > d_e_result[1] and\n",
    "            a_e_result[1] > a_e_result[0]) or\n",
    "            (a_b_result[1] > a_b_result[0] and\n",
    "            b_c_result[1] > b_c_result[0] and\n",
    "            c_d_result[1] > c_d_result[0] and\n",
    "            d_e_result[1] > d_e_result[0] and\n",
    "            a_e_result[0] > a_e_result[1])):\n",
    "\n",
    "            a_rank = team_rankings.get(a, {'Rank': 'N/A', 'Points': 'N/A'})\n",
    "            b_rank = team_rankings.get(b, {'Rank': 'N/A', 'Points': 'N/A'})\n",
    "            c_rank = team_rankings.get(c, {'Rank': 'N/A', 'Points': 'N/A'})\n",
    "            d_rank = team_rankings.get(d, {'Rank': 'N/A', 'Points': 'N/A'})\n",
    "            e_rank = team_rankings.get(e, {'Rank': 'N/A', 'Points': 'N/A'})\n",
    "\n",
    "            valid_combinations.append({\n",
    "                    'Season': season,\n",
    "                    'Week': week,\n",
    "                    'Combo': f'{a}, {b}, {c}, {d}, {e}',\n",
    "                    'Rankings': f'{a_rank[\"Rank\"]}, {b_rank[\"Rank\"]}, {c_rank[\"Rank\"]}, {d_rank[\"Rank\"]}, {e_rank[\"Rank\"]}',\n",
    "                    'ab': f'({a} {b})',\n",
    "                    'a>b': f'{a_b_result[0]}',\n",
    "                    'b>a': f'{a_b_result[1]}',\n",
    "                    'bc': f'({b} {c})',\n",
    "                    'b>c': f'{b_c_result[0]}',\n",
    "                    'c>b': f'{b_c_result[1]}',\n",
    "                    'cd': f'({c} {d})',\n",
    "                    'c>d': f'{c_d_result[0]}',\n",
    "                    'd>c': f'{c_d_result[1]}',\n",
    "                    'de': f'({d} {e})',\n",
    "                    'd>e': f'{d_e_result[0]}',\n",
    "                    'e>d': f'{d_e_result[1]}',\n",
    "                    'ea': f'({e} {a})',\n",
    "                    'e>a': f'{a_e_result[1]}',\n",
    "                    'a>e': f'{a_e_result[0]}'\n",
    "                })\n",
    "\n",
    "    # Convert the valid combinations to a DataFrame\n",
    "    valid_combos_df = pd.DataFrame(valid_combinations)\n",
    "    return valid_combos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_through_5cycle():\n",
    "    seasons = range(2014, 2025)  \n",
    "    weeks = range(1, 18)\n",
    "\n",
    "    all_results_df = pd.DataFrame()\n",
    "\n",
    "    for season in seasons:\n",
    "        for week in weeks:\n",
    "            print(f\"Processing season {season}, week {week}...\")\n",
    "            result_df = cycle_finder_5(season, week)\n",
    "            all_results_df = pd.concat([all_results_df, result_df], ignore_index=True)\n",
    "\n",
    "    # Save the combined DataFrame to a CSV file with a clean format\n",
    "    all_results_df.to_csv(\"./src/college-polls/Pairwise/5_cycle.csv\", index=False)\n",
    "    print(\"All data has been processed and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing season 2014, week 1...\n",
      "Processing season 2014, week 2...\n",
      "Processing season 2014, week 3...\n",
      "Processing season 2014, week 4...\n",
      "Processing season 2014, week 5...\n",
      "Processing season 2014, week 6...\n",
      "Processing season 2014, week 7...\n",
      "Processing season 2014, week 8...\n",
      "Processing season 2014, week 9...\n",
      "Processing season 2014, week 10...\n",
      "Processing season 2014, week 11...\n",
      "Processing season 2014, week 12...\n",
      "Processing season 2014, week 13...\n",
      "Processing season 2014, week 14...\n",
      "Processing season 2014, week 15...\n",
      "Processing season 2014, week 16...\n",
      "Processing season 2014, week 17...\n",
      "Processing season 2015, week 1...\n",
      "Processing season 2015, week 2...\n",
      "No valid data for 2015 and 2\n",
      "Processing season 2015, week 3...\n",
      "Processing season 2015, week 4...\n",
      "Processing season 2015, week 5...\n",
      "Processing season 2015, week 6...\n",
      "Processing season 2015, week 7...\n",
      "Processing season 2015, week 8...\n",
      "Processing season 2015, week 9...\n",
      "Processing season 2015, week 10...\n",
      "Processing season 2015, week 11...\n",
      "Processing season 2015, week 12...\n",
      "Processing season 2015, week 13...\n",
      "Processing season 2015, week 14...\n",
      "Processing season 2015, week 15...\n",
      "Processing season 2015, week 16...\n",
      "Processing season 2015, week 17...\n",
      "No valid data for 2015 and 17\n",
      "Processing season 2016, week 1...\n",
      "Processing season 2016, week 2...\n",
      "Processing season 2016, week 3...\n",
      "Processing season 2016, week 4...\n",
      "Processing season 2016, week 5...\n",
      "Processing season 2016, week 6...\n",
      "Processing season 2016, week 7...\n",
      "Processing season 2016, week 8...\n",
      "Processing season 2016, week 9...\n",
      "Processing season 2016, week 10...\n",
      "Processing season 2016, week 11...\n",
      "Processing season 2016, week 12...\n",
      "Processing season 2016, week 13...\n",
      "Processing season 2016, week 14...\n",
      "Processing season 2016, week 15...\n",
      "Processing season 2016, week 16...\n",
      "Processing season 2016, week 17...\n",
      "No valid data for 2016 and 17\n",
      "Processing season 2017, week 1...\n",
      "Processing season 2017, week 2...\n",
      "Processing season 2017, week 3...\n",
      "Processing season 2017, week 4...\n",
      "Processing season 2017, week 5...\n",
      "Processing season 2017, week 6...\n",
      "Processing season 2017, week 7...\n",
      "Processing season 2017, week 8...\n",
      "Processing season 2017, week 9...\n",
      "Processing season 2017, week 10...\n",
      "Processing season 2017, week 11...\n",
      "Processing season 2017, week 12...\n",
      "Processing season 2017, week 13...\n",
      "Processing season 2017, week 14...\n",
      "Processing season 2017, week 15...\n",
      "Processing season 2017, week 16...\n",
      "Processing season 2017, week 17...\n",
      "No valid data for 2017 and 17\n",
      "Processing season 2018, week 1...\n",
      "Processing season 2018, week 2...\n",
      "Processing season 2018, week 3...\n",
      "Processing season 2018, week 4...\n",
      "Processing season 2018, week 5...\n",
      "Processing season 2018, week 6...\n",
      "Processing season 2018, week 7...\n",
      "Processing season 2018, week 8...\n",
      "Processing season 2018, week 9...\n",
      "Processing season 2018, week 10...\n",
      "Processing season 2018, week 11...\n",
      "Processing season 2018, week 12...\n",
      "Processing season 2018, week 13...\n",
      "Processing season 2018, week 14...\n",
      "Processing season 2018, week 15...\n",
      "Processing season 2018, week 16...\n",
      "Processing season 2018, week 17...\n",
      "No valid data for 2018 and 17\n",
      "Processing season 2019, week 1...\n",
      "Processing season 2019, week 2...\n",
      "Processing season 2019, week 3...\n",
      "Processing season 2019, week 4...\n",
      "Processing season 2019, week 5...\n",
      "Processing season 2019, week 6...\n",
      "Processing season 2019, week 7...\n",
      "Processing season 2019, week 8...\n",
      "Processing season 2019, week 9...\n",
      "Processing season 2019, week 10...\n",
      "Processing season 2019, week 11...\n",
      "Processing season 2019, week 12...\n",
      "Processing season 2019, week 13...\n",
      "Processing season 2019, week 14...\n",
      "Processing season 2019, week 15...\n",
      "Processing season 2019, week 16...\n",
      "Processing season 2019, week 17...\n",
      "Processing season 2020, week 1...\n",
      "Processing season 2020, week 2...\n",
      "Processing season 2020, week 3...\n",
      "Processing season 2020, week 4...\n",
      "Processing season 2020, week 5...\n",
      "Processing season 2020, week 6...\n",
      "Processing season 2020, week 7...\n",
      "Processing season 2020, week 8...\n",
      "Processing season 2020, week 9...\n",
      "Processing season 2020, week 10...\n",
      "Processing season 2020, week 11...\n",
      "Processing season 2020, week 12...\n",
      "Processing season 2020, week 13...\n",
      "Processing season 2020, week 14...\n",
      "Processing season 2020, week 15...\n",
      "Processing season 2020, week 16...\n",
      "Processing season 2020, week 17...\n",
      "Processing season 2021, week 1...\n",
      "Processing season 2021, week 2...\n",
      "Processing season 2021, week 3...\n",
      "Processing season 2021, week 4...\n",
      "Processing season 2021, week 5...\n",
      "Processing season 2021, week 6...\n",
      "Processing season 2021, week 7...\n",
      "Processing season 2021, week 8...\n",
      "Processing season 2021, week 9...\n",
      "Processing season 2021, week 10...\n",
      "Processing season 2021, week 11...\n",
      "Processing season 2021, week 12...\n",
      "Processing season 2021, week 13...\n",
      "Processing season 2021, week 14...\n",
      "Processing season 2021, week 15...\n",
      "Processing season 2021, week 16...\n",
      "Processing season 2021, week 17...\n",
      "No valid data for 2021 and 17\n",
      "Processing season 2022, week 1...\n",
      "Processing season 2022, week 2...\n",
      "Processing season 2022, week 3...\n",
      "Processing season 2022, week 4...\n",
      "Processing season 2022, week 5...\n",
      "Processing season 2022, week 6...\n",
      "Processing season 2022, week 7...\n",
      "Processing season 2022, week 8...\n",
      "Processing season 2022, week 9...\n",
      "Processing season 2022, week 10...\n",
      "Processing season 2022, week 11...\n",
      "Processing season 2022, week 12...\n",
      "Processing season 2022, week 13...\n",
      "Processing season 2022, week 14...\n",
      "Processing season 2022, week 15...\n",
      "Processing season 2022, week 16...\n",
      "Processing season 2022, week 17...\n",
      "No valid data for 2022 and 17\n",
      "Processing season 2023, week 1...\n",
      "Processing season 2023, week 2...\n",
      "Processing season 2023, week 3...\n",
      "Processing season 2023, week 4...\n",
      "Processing season 2023, week 5...\n",
      "Processing season 2023, week 6...\n",
      "Processing season 2023, week 7...\n",
      "Processing season 2023, week 8...\n",
      "Processing season 2023, week 9...\n",
      "Processing season 2023, week 10...\n",
      "Processing season 2023, week 11...\n",
      "Processing season 2023, week 12...\n",
      "Processing season 2023, week 13...\n",
      "Processing season 2023, week 14...\n",
      "Processing season 2023, week 15...\n",
      "Processing season 2023, week 16...\n",
      "Processing season 2023, week 17...\n",
      "No valid data for 2023 and 17\n",
      "Processing season 2024, week 1...\n",
      "Processing season 2024, week 2...\n",
      "Processing season 2024, week 3...\n",
      "Processing season 2024, week 4...\n",
      "Processing season 2024, week 5...\n",
      "Processing season 2024, week 6...\n",
      "No valid data for 2024 and 6\n",
      "Processing season 2024, week 7...\n",
      "No valid data for 2024 and 7\n",
      "Processing season 2024, week 8...\n",
      "No valid data for 2024 and 8\n",
      "Processing season 2024, week 9...\n",
      "No valid data for 2024 and 9\n",
      "Processing season 2024, week 10...\n",
      "No valid data for 2024 and 10\n",
      "Processing season 2024, week 11...\n",
      "No valid data for 2024 and 11\n",
      "Processing season 2024, week 12...\n",
      "No valid data for 2024 and 12\n",
      "Processing season 2024, week 13...\n",
      "No valid data for 2024 and 13\n",
      "Processing season 2024, week 14...\n",
      "No valid data for 2024 and 14\n",
      "Processing season 2024, week 15...\n",
      "No valid data for 2024 and 15\n",
      "Processing season 2024, week 16...\n",
      "No valid data for 2024 and 16\n",
      "Processing season 2024, week 17...\n",
      "No valid data for 2024 and 17\n",
      "All data has been processed and saved\n"
     ]
    }
   ],
   "source": [
    "cycle_through_5cycle()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
